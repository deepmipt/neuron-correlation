{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Integration tests `class TestTrainRepeatedly`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=green> Method `TestTrainRepeatedly.test_dataset_tensor_saving()`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `check_summarized_step_dirs_for_tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_TENSORS_CONFIG = {\n",
    "    \"tensor2\": {\n",
    "        \"module\": \"tensorflow\",\n",
    "        \"function\": \"ones\",\n",
    "        \"args\": [[3, 5]]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tests.integration.test_integration as module\n",
    "\n",
    "\n",
    "t2 = tf.ones([3, 5])\n",
    "\n",
    "s2 = tf.summary.tensor_summary('tensor2', t2)\n",
    "\n",
    "path = os.path.expanduser(\n",
    "    '~/neuron-correlation/results_of_tests/integration/'\n",
    "    'test_mnist/train_repeatedly/0/dataset_tensors/'\n",
    ")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for j in range(0, 20, 2):\n",
    "        logdir = os.path.join(path, 'tensor2', str(j))\n",
    "        w = tf.summary.FileWriter(logdir=logdir)\n",
    "        for i in range(0, 100, 3):\n",
    "            s_2 = sess.run(s2)\n",
    "            w.add_summary(s_2, global_step=i)\n",
    "        w.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tests.integration.test_integration as module\n",
    "\n",
    "path = os.path.expanduser(\n",
    "    '~/neuron-correlation/results_of_tests/integration'\n",
    "    '/test_mnist/train_repeatedly/0/dataset_tensors/tensor2'\n",
    ")\n",
    "\n",
    "tensor_values = module.get_summary_tensors_values(SUMMARY_TENSORS_CONFIG)\n",
    "tensor_steps = {\n",
    "    \"tensor2\": {\n",
    "        \"train\": list(range(0, 20, 2)),\n",
    "        \"dataset\": list(range(0, 100, 3))\n",
    "    }\n",
    "}\n",
    "\n",
    "report = module.check_summarized_step_dirs_for_tensor(\n",
    "    path,\n",
    "    'tensor2',\n",
    "    tensor_values['tensor2'],\n",
    "    tensor_steps['tensor2'],\n",
    ")\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "### Function `check_ds_summarized_in_launch_dir()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "SUMMARY_TENSORS_CONFIG = {\n",
    "    \"tensor1\": {\n",
    "        \"module\": \"tensorflow\",\n",
    "        \"function\": \"zeros\",\n",
    "        \"args\": [[2, 9]]\n",
    "    },\n",
    "    \"tensor2\": {\n",
    "        \"module\": \"tensorflow\",\n",
    "        \"function\": \"ones\",\n",
    "        \"args\": [[3, 5]]\n",
    "    }\n",
    "}\n",
    "\n",
    "DATASET_TENSORS_SUMMARY_CONFIG = {\n",
    "    \"tensor1\": {\n",
    "        \"type\": \"mean\",\n",
    "        \"dataset\": {\n",
    "            \"tfds.load\": {\n",
    "                \"name\": \"mnist:3.*.*\",\n",
    "                \"split\": \"test[:1%]\",\n",
    "                \"batch_size\": 100,\n",
    "                \"as_supervised\": True\n",
    "            }\n",
    "        },\n",
    "        \"train_steps\": {\n",
    "            \"counter\": \"step\",\n",
    "            \"type\": \"true_on_range\",\n",
    "            \"step\": 1000,\n",
    "            \"include_stop\": True\n",
    "        },\n",
    "        \"indices_of_batches\": {\n",
    "            \"counter\": \"step\",\n",
    "            \"type\": \"true_on_range\",\n",
    "            \"step\": 1,\n",
    "            \"include_stop\": True\n",
    "        }\n",
    "    },\n",
    "    \"tensor2\": {\n",
    "        \"type\": \"all\",\n",
    "        \"dataset\": {\n",
    "            \"tfds.load\": {\n",
    "                \"name\": \"mnist:3.*.*\",\n",
    "                \"split\": \"test[:1%]\",\n",
    "                \"batch_size\": 100,\n",
    "                \"as_supervised\": True\n",
    "            }\n",
    "        },\n",
    "        \"train_steps\": {\n",
    "            \"counter\": \"step\",\n",
    "            \"type\": \"true_on_logrange\",\n",
    "            \"init\": 0,\n",
    "            \"factor\": 1.02,\n",
    "            \"include_stop\": True\n",
    "        },\n",
    "        \"indices_of_batches\": {\n",
    "            \"counter\": \"step\",\n",
    "            \"type\": \"true_on_range\",\n",
    "            \"step\": 3,\n",
    "            \"include_stop\": True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "path = os.path.expanduser(\n",
    "    '~/neuron-correlation/results_of_tests/integration'\n",
    "    '/test_mnist/train_repeatedly/dataset_tensors/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tests.integration.test_integration as module\n",
    "\n",
    "\n",
    "def create_step_dir_tensors(path, i, step):\n",
    "    d_all = os.path.join(\n",
    "        path, str(i), 'dataset_tensors', 'tensor2', str(step))\n",
    "    w_all = tf.summary.FileWriter(logdir=d_all)\n",
    "    for k in range(0, 100, 3):\n",
    "        s_2 = sess.run(s2)\n",
    "        w_all.add_summary(s_2, global_step=k)\n",
    "    w_all.flush()\n",
    "\n",
    "\n",
    "t1 = tf.zeros([2, 9])\n",
    "t2 = tf.ones([3, 5])\n",
    "\n",
    "s1 = tf.summary.tensor_summary('tensor1', t1)\n",
    "s2 = tf.summary.tensor_summary('tensor2', t2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    dir_ = os.path.join(\n",
    "        path, '0', 'dataset_tensors', 'tensor1')\n",
    "    w = tf.summary.FileWriter(logdir=dir_)\n",
    "    for j in range(0, 150000, 5000):\n",
    "        s_1 = sess.run(s1)\n",
    "        w.add_summary(s_1, global_step=j)\n",
    "    w.flush()\n",
    "    step = 0\n",
    "    factor = 1.3\n",
    "    while step < 150000:\n",
    "        create_step_dir_tensors(path, 0, step)\n",
    "        new_step = int(np.ceil(step*factor))\n",
    "        if new_step == step:\n",
    "            new_step += 1\n",
    "        step = new_step\n",
    "    create_step_dir_tensors(path, 0, 150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tests.integration.test_integration as module\n",
    "\n",
    "\n",
    "def custom_logrange(start, stop, factor, include_stop=False):\n",
    "    values = []\n",
    "    while start < stop:\n",
    "        values.append(start)\n",
    "        if start >= int(start * factor):\n",
    "            start += 1\n",
    "        else:\n",
    "            start = int(start * factor) + int(start * factor % 1 > 0)\n",
    "    if include_stop:\n",
    "        values.append(stop)\n",
    "    return values\n",
    "\n",
    "\n",
    "path = os.path.expanduser(\n",
    "    '~/neuron-correlation/results_of_tests/integration'\n",
    "    '/test_mnist/train_repeatedly/dataset_tensors/0/dataset_tensors'\n",
    ")\n",
    "\n",
    "tensor_values = module.get_summary_tensors_values(SUMMARY_TENSORS_CONFIG)\n",
    "tensor_steps = {\n",
    "    \"tensor1\": {\n",
    "        \"train\": list(range(0, 150000, 5000)),\n",
    "        \"datasets\": list(range(9999))\n",
    "    },\n",
    "    \"tensor2\": {\n",
    "        \"train\": custom_logrange(0, 150000, 1.3, True),\n",
    "        \"dataset\": list(range(0, 100, 3))\n",
    "    }\n",
    "}\n",
    "\n",
    "report = module.check_ds_summarized_in_launch_dir(\n",
    "    DATASET_TENSORS_SUMMARY_CONFIG,\n",
    "    path,\n",
    "    tensor_values,\n",
    "    tensor_steps,\n",
    ")\n",
    "\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "### Function `get_ds_tensors_err_msg()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tests.integration.test_integration as module\n",
    "\n",
    "\n",
    "SUMMARY_TENSORS_CONFIG = {\n",
    "    \"tensor1\": {\n",
    "        \"module\": \"tensorflow\",\n",
    "        \"function\": \"zeros\",\n",
    "        \"args\": [[2, 9]]\n",
    "    },\n",
    "    \"tensor2\": {\n",
    "        \"module\": \"tensorflow\",\n",
    "        \"function\": \"ones\",\n",
    "        \"args\": [[3, 5]]\n",
    "    }\n",
    "}\n",
    "\n",
    "DATASET_TENSORS_SUMMARY_CONFIG = {\n",
    "    \"tensor1\": {\n",
    "        \"type\": \"mean\",\n",
    "        \"dataset\": {\n",
    "            \"tfds.load\": {\n",
    "                \"name\": \"mnist:3.*.*\",\n",
    "                \"split\": \"test[:1%]\",\n",
    "                \"batch_size\": 100,\n",
    "                \"as_supervised\": True\n",
    "            }\n",
    "        },\n",
    "        \"train_steps\": {\n",
    "            \"counter\": \"step\",\n",
    "            \"type\": \"true_on_range\",\n",
    "            \"step\": 1000,\n",
    "            \"include_stop\": True\n",
    "        },\n",
    "        \"indices_of_batches\": {\n",
    "            \"counter\": \"step\",\n",
    "            \"type\": \"true_on_range\",\n",
    "            \"step\": 1,\n",
    "            \"include_stop\": True\n",
    "        }\n",
    "    },\n",
    "    \"tensor2\": {\n",
    "        \"type\": \"all\",\n",
    "        \"dataset\": { \n",
    "            \"tfds.load\": {\n",
    "                \"name\": \"mnist:3.*.*\",\n",
    "                \"split\": \"test[:1%]\",\n",
    "                \"batch_size\": 100,\n",
    "                \"as_supervised\": True\n",
    "            }\n",
    "        },\n",
    "        \"train_steps\": {\n",
    "            \"counter\": \"step\",\n",
    "            \"type\": \"true_on_logrange\",\n",
    "            \"init\": 0,\n",
    "            \"factor\": 1.02,\n",
    "            \"include_stop\": True\n",
    "        },\n",
    "        \"indices_of_batches\": {\n",
    "            \"counter\": \"step\",\n",
    "            \"type\": \"true_on_range\",\n",
    "            \"step\": 3,\n",
    "            \"include_stop\": True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "report = {\n",
    "    'ok': True,\n",
    "    'tensor1': {\n",
    "        'ok': True,\n",
    "        'missing_steps': [],\n",
    "        'unwanted_steps': [],\n",
    "        'wrong_results': [],\n",
    "        'expected_value': np.array(\n",
    "            [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "             [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
    "        ),\n",
    "        'expected_shape': (2, 9)\n",
    "    },\n",
    "    'tensor2': {\n",
    "        'ok': True,\n",
    "        'wrong_results': [],\n",
    "        'missing_steps': [],\n",
    "        'unwanted_steps': [],\n",
    "        'expected_value': np.array(\n",
    "            [[1., 1., 1., 1., 1.],\n",
    "             [1., 1., 1., 1., 1.],\n",
    "             [1., 1., 1., 1., 1.]],\n",
    "        ),\n",
    "        'expected_shape': (3, 5)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "msg = module.get_ds_tensors_err_msg(\n",
    "    \"my_launch_dir\",\n",
    "    report,\n",
    "    SUMMARY_TENSORS_CONFIG,\n",
    "    DATASET_TENSORS_SUMMARY_CONFIG\n",
    ")\n",
    "\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "### Method `TestTrainRepeatedly.test_dataset_tensor_saving()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tests.integration.test_integration as module\n",
    "\n",
    "\n",
    "def create_step_dir_tensors(path, i, step):\n",
    "    d_all = os.path.join(\n",
    "        path, str(i), 'dataset_tensors', 'tensor2', str(step))\n",
    "    w_all = tf.summary.FileWriter(logdir=d_all)\n",
    "    for k in range(0, 100, 3):\n",
    "        s_2 = sess.run(s2)\n",
    "        w_all.add_summary(s_2, global_step=k)\n",
    "    s_2 = sess.run(s2)\n",
    "    w_all.add_summary(s_2, global_step=100)\n",
    "    w_all.flush()\n",
    "\n",
    "\n",
    "path = os.path.expanduser(\n",
    "    '~/neuron-correlation/results_of_tests/integration'\n",
    "    '/test_mnist/train_repeatedly/dataset_tensors/'\n",
    ")\n",
    "\n",
    "t1 = tf.zeros([2, 9])\n",
    "t2 = tf.ones([3, 5])\n",
    "\n",
    "s1 = tf.summary.tensor_summary('tensor1', t1)\n",
    "s2 = tf.summary.tensor_summary('tensor2', t2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        d_mean = os.path.join(\n",
    "            path, str(i), 'dataset_tensors', 'tensor1')\n",
    "        w_mean = tf.summary.FileWriter(logdir=d_mean)\n",
    "        for j in range(0, 150001, 10000):\n",
    "            s_1 = sess.run(s1)\n",
    "            w_mean.add_summary(s_1, global_step=j)\n",
    "        w_mean.flush()\n",
    "        step = 0\n",
    "        factor = 1.3\n",
    "        while step < 150000:\n",
    "            create_step_dir_tensors(path, i, step)\n",
    "            new_step = int(np.ceil(step*factor))\n",
    "            if new_step == step:\n",
    "                new_step += 1\n",
    "            step = new_step\n",
    "        create_step_dir_tensors(path, i, 150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tests.integration.test_integration as module\n",
    "\n",
    "\n",
    "ttr = module.TestTrainRepeatedly()\n",
    "report = ttr.test_dataset_tensor_saving()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
